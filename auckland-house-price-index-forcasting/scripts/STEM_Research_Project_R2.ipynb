{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40d2f43-eb22-4a6e-8275-d0fc2030c005",
   "metadata": {},
   "source": [
    "## Forecasting Auckland’s Monthly House Price Index (2018–2025): Transparent Time-Series Baselines with Causal Exogenous Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1cf82-457b-4996-80e7-0991e9e69c96",
   "metadata": {},
   "source": [
    "### Student ID: 24251155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8169a62-bf58-4952-a1ab-b98094ed8552",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "  - Build a transparent pipeline for forecasting log(HPI) at horizons h={1,3,6,12}\n",
    "  - Champions chosen by rolling-origin CV (2018-01→2024-08), audited on TEST (targets 2024-09→2025-08)\n",
    "  - Baselines: Seasonal-naïve, ETS; Models: ARIMA, ARIMAX (with 4 pre-registered drivers)\n",
    "  - Causal imputation happens IN-MEMORY here; we also export the exact imputed panel for audit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdc8bd-eac7-4810-9874-de55bb3c974f",
   "metadata": {},
   "source": [
    "### Analysis policy abstract:\n",
    "  - Main ARIMAX drivers (lagged, causal): mortgage rate (L1), migration (L2), consents (L4), filled jobs (L1)\n",
    "  - Additional variables (OCR, listings, total stock, sales, days-to-sell, median price) are screened and reported\n",
    "    in the Appendix, but are NOT added to the main model (avoid leakage/post-hoc feature creep).\n",
    "  - We keep “total_stock_akl_imp_lag1” as a robustness variant in Appendix only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc216fea-63a7-414c-a0b6-32cabf95acdc",
   "metadata": {},
   "source": [
    "### Outputs (saved in OUT_DIR):\n",
    "  - panel_summary.csv\n",
    "  - monthly_panel.csv\n",
    "  - monthly_panel_imputed_causal.csv\n",
    "  - imputation_report_causal.csv\n",
    "  - cv_metrics_log_nonseasonal.csv\n",
    "  - cv_metrics_log_seasonal.csv\n",
    "  - cv_champions_by_horizon.csv\n",
    "  - cv_allmodels_logrmse.csv\n",
    "  - test_predictions_laststep.csv\n",
    "  - final_test_champions_by_horizon.csv\n",
    "  - test_dm_winner_vs_snaive.csv\n",
    "  - test_metrics_winners_level.csv\n",
    "  - test_metrics_level_allmodels.csv\n",
    "  - test_metrics_log_allmodels.csv\n",
    "  - plots_test/test_actual_vs_winner_h{1,3,6,12}.png\n",
    "  - appendix_leadlag_corr.csv\n",
    "  - appendix_oos_singlevar_rmse.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b01c62-f0e5-456e-8e94-646978b9a8a4",
   "metadata": {},
   "source": [
    "### Step 0: Main CSV File Creation\n",
    "- Compiling all raw csv data files to one main output csv file\n",
    "- Dropping duplicates for dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c48a0f2-abe3-4509-a2f3-6ade1e937c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: C:\\Users\\icora\\AUT Lab Learning\n",
      "DATA: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\Extracted_Data_from_Original_Data_for_Analysis\n",
      "DATA exists: True\n",
      "DATA files: ['offical_cash_rate_(ocr).csv', 'rbnz_mortgage_rates_b20.csv', 'realestate_nz_listings_auckland.csv', 'reinz_auckland_hpi.csv', 'reinz_auckland_market_activity.csv', 'stats_nz_building_consents_auckland.csv', 'stats_nz_mei_filled_jobs_nz.csv', 'stats_nz_net_migration_nz.csv']\n",
      "Wrote: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\monthly_panel.csv\n"
     ]
    }
   ],
   "source": [
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "BASE = os.path.abspath(os.getcwd())\n",
    "DATA = r\"C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\Extracted_Data_from_Original_Data_for_Analysis\"\n",
    "OUT  = os.path.join(os.path.dirname(DATA), \"output\")  # C:\\...\\Data_Collection\\output\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "def _read_csv(name, parse_dates=True):\n",
    "    path = os.path.join(DATA, name)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"WARNING: {name} not found, skipping.\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    if parse_dates and \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], utc=False)\n",
    "        # force month-end for alignment\n",
    "        df[\"date\"] = df[\"date\"] + pd.offsets.MonthEnd(0)\n",
    "    return df\n",
    "\n",
    "def _merge(left, right):\n",
    "    if left is None:\n",
    "        return right\n",
    "    if right is None:\n",
    "        return left\n",
    "    return pd.merge(left, right, on=\"date\", how=\"outer\")\n",
    "\n",
    "def build_panel():\n",
    "    dfs = []\n",
    "    dfs.append(_read_csv(\"reinz_auckland_hpi.csv\"))\n",
    "    dfs.append(_read_csv(\"rbnz_mortgage_rates_b20.csv\"))\n",
    "    dfs.append(_read_csv(\"offical_cash_rate_(ocr).csv\"))\n",
    "    dfs.append(_read_csv(\"stats_nz_building_consents_auckland.csv\"))\n",
    "    dfs.append(_read_csv(\"stats_nz_net_migration_nz.csv\"))\n",
    "    dfs.append(_read_csv(\"stats_nz_mei_filled_jobs_nz.csv\"))\n",
    "    dfs.append(_read_csv(\"realestate_nz_listings_auckland.csv\"))\n",
    "    dfs.append(_read_csv(\"reinz_auckland_market_activity.csv\"))\n",
    "\n",
    "    panel = None\n",
    "    for d in dfs:\n",
    "        panel = _merge(panel, d)\n",
    "\n",
    "    # If nothing loaded\n",
    "    if panel is None or panel.empty:\n",
    "        raise RuntimeError(\"No data loaded. Check filenames/columns in DATA folder.\")\n",
    "\n",
    "    # Sort and drop duplicates\n",
    "    panel = panel.sort_values(\"date\").drop_duplicates(\"date\")\n",
    "\n",
    "    # Ensure monthly frequency index (use 'ME' = month end)\n",
    "    panel = panel.set_index(\"date\").asfreq(\"ME\")\n",
    "\n",
    "    # Target transformations\n",
    "    if \"hpi_index\" in panel.columns:\n",
    "        panel[\"y_log\"] = np.log(panel[\"hpi_index\"])\n",
    "        panel[\"y_diff\"] = panel[\"y_log\"].diff()\n",
    "    else:\n",
    "        print(\"WARNING: hpi_index not found. Please populate reinz_auckland_hpi.csv\")\n",
    "\n",
    "    # Create lags for market activity (avoid look-ahead)\n",
    "    for col in [\"sales_count_akl\", \"days_to_sell_akl\"]:\n",
    "        if col in panel.columns:\n",
    "            for L in [1, 2, 3]:\n",
    "                panel[f\"{col}_lag{L}\"] = panel[col].shift(L)\n",
    "\n",
    "    # Simple sanity outputs\n",
    "    summary = panel.describe(include=\"all\")\n",
    "    summary.to_csv(os.path.join(OUT, \"panel_summary.csv\"))\n",
    "    out_path = os.path.join(OUT, \"monthly_panel.csv\")\n",
    "    panel.to_csv(out_path)\n",
    "    print(f\"Wrote: {out_path}\")\n",
    "    return panel\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"BASE:\", BASE)\n",
    "    print(\"DATA:\", DATA)\n",
    "    print(\"DATA exists:\", os.path.exists(DATA))\n",
    "    if os.path.exists(DATA):\n",
    "        print(\"DATA files:\", os.listdir(DATA))  \n",
    "    build_panel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ce1c4-017d-465f-81b6-14f1f38ae54a",
   "metadata": {},
   "source": [
    "### Step 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f9a03f-7a41-41a9-836b-ddc13b604016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== 1) Imports & Config =============================\n",
    "import os, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import DateOffset, MonthEnd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.float_format\", lambda v: f\"{v:,.6f}\")\n",
    "\n",
    "# ---- Paths (edit OUT_DIR only) ----\n",
    "OUT_DIR = r\"C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\"\n",
    "PANEL_PATH = os.path.join(OUT_DIR, \"monthly_panel.csv\")\n",
    "\n",
    "# ---- Timeline windows (month-end timestamps) ----\n",
    "TRAIN_END  = pd.Timestamp(\"2024-08-31\")  # CV window ends by origin\n",
    "TEST_START = pd.Timestamp(\"2024-09-30\")  # test window by TARGET month (month-end)\n",
    "TEST_END   = pd.Timestamp(\"2025-08-31\")\n",
    "\n",
    "# ---- Evaluation settings ----\n",
    "MIN_TRAIN    = 24\n",
    "HORIZONS     = (1, 3, 6, 12)\n",
    "ARIMA_ORDERS = [(1,1,0), (0,1,1), (1,1,1)]\n",
    "TARGET       = \"y_log_imp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cad67f-a93e-4e28-ab14-7ed581175d2b",
   "metadata": {},
   "source": [
    "### Step 2: Causal Imputation (in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd7bb8c-d07a-4711-838d-bbf061d89401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== 2) Causal Imputation (in-memory) =======================\n",
    "\n",
    "def _seasonal_fill_causal(s: pd.Series):\n",
    "    \"\"\"Same-month-last-year → month-of-year median (past only) → forward-fill.\"\"\"\n",
    "    s = s.copy().asfreq(\"M\")\n",
    "    idx = s.index\n",
    "    miss = s.isna()\n",
    "    if not miss.any(): return s\n",
    "    # 1) same month last year\n",
    "    for i in np.where(miss)[0]:\n",
    "        t = idx[i]; ly = t - pd.DateOffset(years=1)\n",
    "        if ly in idx and pd.notna(s.loc[ly]):\n",
    "            s.iloc[i] = s.loc[ly]\n",
    "    # 2) month-of-year median from past\n",
    "    if s.isna().any():\n",
    "        moy = s.index.month\n",
    "        for i in np.where(s.isna())[0]:\n",
    "            m = moy[i]\n",
    "            hist = s[(moy==m) & (s.index < s.index[i])].dropna()\n",
    "            if len(hist) >= 3:\n",
    "                s.iloc[i] = hist.median()\n",
    "    # 3) causal fallback\n",
    "    return s.ffill()\n",
    "\n",
    "def _interp_fill_causal(s: pd.Series, nonneg=False):\n",
    "    x = s.asfreq(\"M\").ffill()\n",
    "    return x.clip(lower=0) if nonneg else x\n",
    "\n",
    "def build_imputed_panel(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create *_imp, *_miss, and y_* transforms causally. No disk writes here.\"\"\"\n",
    "    df = df_raw.copy().asfreq(\"M\")\n",
    "\n",
    "    # Target (HPI)\n",
    "    if \"hpi_index\" in df.columns:\n",
    "        df[\"hpi_index_imp\"] = _interp_fill_causal(df[\"hpi_index\"])\n",
    "        df[\"y_log_imp\"]     = np.log(df[\"hpi_index_imp\"])\n",
    "        df[\"y_diff_imp\"]    = df[\"y_log_imp\"].diff()\n",
    "\n",
    "    # Rates / OCR (clip 0..25)\n",
    "    for c in [\"mort_rate_1y\", \"mort_rate_float\", \"ocr\"]:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}_miss\"] = df[c].isna().astype(int)\n",
    "            df[f\"{c}_imp\"]  = _interp_fill_causal(df[c], nonneg=True).clip(0, 25)\n",
    "\n",
    "    # Seasonal counts (+round)\n",
    "    for c in [\"dwellings_consent_count\",\"new_listings_akl\",\"total_stock_akl\",\n",
    "              \"sales_count_akl\",\"days_to_sell_akl\",\"median_price_akl\"]:\n",
    "        if c in df.columns:\n",
    "            df[f\"{c}_miss\"] = df[c].isna().astype(int)\n",
    "            df[f\"{c}_imp\"]  = np.rint(_seasonal_fill_causal(df[c]).clip(lower=0)).astype(float)\n",
    "\n",
    "    # Smooth activity\n",
    "    if \"filled_jobs_nz\" in df.columns:\n",
    "        df[\"filled_jobs_nz_miss\"] = df[\"filled_jobs_nz\"].isna().astype(int)\n",
    "        df[\"filled_jobs_nz_imp\"]  = np.rint(_interp_fill_causal(df[\"filled_jobs_nz\"], nonneg=True)).astype(float)\n",
    "\n",
    "    if \"net_migration_nz\" in df.columns:\n",
    "        df[\"net_migration_nz_miss\"] = df[\"net_migration_nz\"].isna().astype(int)\n",
    "        df[\"net_migration_nz_imp\"]  = _interp_fill_causal(df[\"net_migration_nz\"], nonneg=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba115ec1-e554-4a34-8ffd-cb65a5e91608",
   "metadata": {},
   "source": [
    "### Step 3: Features (Exogenous Regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e320ac-93ed-4b98-951c-666a38e27530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 3) Features =============================\n",
    "\n",
    "def add_lags(df, col, lags):\n",
    "    for L in lags:\n",
    "        df[f\"{col}_lag{L}\"] = df[col].shift(L)\n",
    "    return df\n",
    "\n",
    "def build_exog(df):\n",
    "    \"\"\"\n",
    "    Main ARIMAX drivers only (pre-registered, causal lags):\n",
    "      - mort_rate_1y_imp (L1), net_migration_nz_imp (L2),\n",
    "        dwellings_consent_count_imp (L4), filled_jobs_nz_imp (L1)\n",
    "    Also include lagged *_miss flags to signal imputed periods.\n",
    "    \"\"\"\n",
    "    exog_lags = {\n",
    "        \"mort_rate_1y_imp\": [1],\n",
    "        \"net_migration_nz_imp\": [2],\n",
    "        \"dwellings_consent_count_imp\": [4],\n",
    "        \"filled_jobs_nz_imp\": [1],\n",
    "    }\n",
    "    EXO = []\n",
    "    for c, lags in exog_lags.items():\n",
    "        if c in df.columns:\n",
    "            add_lags(df, c, lags)\n",
    "            EXO += [f\"{c}_lag{L}\" for L in lags]\n",
    "\n",
    "    for base in [\"mort_rate_1y_miss\",\"net_migration_nz_miss\",\n",
    "                 \"dwellings_consent_count_miss\",\"filled_jobs_nz_miss\"]:\n",
    "        if base in df.columns:\n",
    "            add_lags(df, base, [1])\n",
    "            EXO.append(f\"{base}_lag1\")\n",
    "\n",
    "    return df, EXO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d580eb-104a-4f39-8fef-8cf39c763c0d",
   "metadata": {},
   "source": [
    "### Step 4: Models - ETS & (S)ARIMA / ARIMAX fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0286c2-9461-45fd-b603-ad66c632dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ 4) Models: ETS & (S)ARIMA / ARIMAX fitters ===================\n",
    "\n",
    "def fit_ets(y: pd.Series):\n",
    "    \"\"\"ETS A/A if long enough; otherwise simple level.\"\"\"\n",
    "    if len(y) < 24:\n",
    "        return ExponentialSmoothing(y, trend=None, seasonal=None).fit()\n",
    "    return ExponentialSmoothing(y, trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()\n",
    "\n",
    "def fit_sarimax(y, X, order, seasonal_flag):\n",
    "    seas = (0,0,0,0) if not seasonal_flag else (0,1,1,12)\n",
    "    return SARIMAX(y, exog=X, order=order, seasonal_order=seas,\n",
    "                   enforce_stationarity=False, enforce_invertibility=False\n",
    "                  ).fit(disp=False, maxiter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8e0b9-871e-431d-913f-6c7cc91e9425",
   "metadata": {},
   "source": [
    "### Step 5: Metrics & Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46305694-f0ca-44a8-8d34-614dbad3b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================= 5) Metrics & Tests ==============================\n",
    "\n",
    "def metrics_table(df, label=\"log\"):\n",
    "    out=[]\n",
    "    for h, g in df.groupby(\"h\"):\n",
    "        y = g[\"y_true\"].values\n",
    "        def metr(col):\n",
    "            e = y - g[col].values\n",
    "            return dict(MAE=float(np.mean(np.abs(e))),\n",
    "                        RMSE=float(np.sqrt(np.mean(e**2))),\n",
    "                        MAPE=float(np.mean(np.abs(e/np.where(np.abs(y)<1e-12, np.nan, y)))*100))\n",
    "        row = {\"h\": int(h), \"scale\": label}\n",
    "        for m in [\"snaive\",\"ets\",\"arima\",\"arimax\"]:\n",
    "            if m in g.columns:\n",
    "                row.update({f\"{m}_{k}\": v for k,v in metr(m).items()})\n",
    "        out.append(row)\n",
    "    return pd.DataFrame(out).sort_values(\"h\")\n",
    "\n",
    "def _normal_cdf(x): return 0.5*(1.0+math.erf(x/math.sqrt(2.0)))\n",
    "\n",
    "def dm_test(e_model, e_base, h):\n",
    "    \"\"\"\n",
    "    Diebold–Mariano test on squared errors; small-sample lag cap L = min(h-1, T//4, >=1).\n",
    "    Returns (stat, p).\n",
    "    \"\"\"\n",
    "    e1, e2 = np.asarray(e_model), np.asarray(e_base)\n",
    "    d = (e1**2 - e2**2); dbar = np.mean(d); T = len(d)\n",
    "    if T < 3: return np.nan, np.nan\n",
    "    L = min(max(h-1,1), max(1, T//4))\n",
    "    gamma0 = np.var(d, ddof=1)\n",
    "    cov = 0.0\n",
    "    for l in range(1, L+1):\n",
    "        wl = 1 - l/(L+1)\n",
    "        cov += 2*wl*np.cov(d[l:], d[:-l], ddof=1)[0,1]\n",
    "    var = (gamma0 + cov)/T\n",
    "    if not np.isfinite(var) or var<=0: return np.nan, np.nan\n",
    "    stat = dbar/np.sqrt(var); p = 2*(1-_normal_cdf(abs(stat)))\n",
    "    return float(stat), float(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67cad4-23d5-4b4e-b143-2eff8f72c832",
   "metadata": {},
   "source": [
    "### Step 6: Rolling-origin cross-validation (model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4845161-f384-4cfa-9060-b19b7c5ce3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 6) Rolling-origin CV ===============================\n",
    "\n",
    "def evaluate_cv(df_base, seasonal_flag, target=TARGET,\n",
    "                horizons=HORIZONS, arima_orders=ARIMA_ORDERS, min_train=MIN_TRAIN):\n",
    "    df = df_base.copy()\n",
    "    df, EXO = build_exog(df)\n",
    "    df = df.loc[:TRAIN_END].dropna(subset=[target] + EXO)\n",
    "    dates = df.index\n",
    "\n",
    "    rows=[]\n",
    "    for t_idx in range(max(min_train, 0), len(dates)-1):\n",
    "        origin = dates[t_idx]\n",
    "        y_tr   = df.loc[:origin, target]\n",
    "        X_tr   = df.loc[:origin, EXO] if EXO else None\n",
    "\n",
    "        # ETS fit\n",
    "        ets_fit = None\n",
    "        try: ets_fit = fit_ets(y_tr)\n",
    "        except Exception: pass\n",
    "\n",
    "        # Best ARIMA by AIC\n",
    "        best_arima, best_aic = None, np.inf\n",
    "        for od in arima_orders:\n",
    "            try:\n",
    "                m = fit_sarimax(y_tr, None, od, seasonal_flag)\n",
    "                if m.aic < best_aic: best_arima, best_aic = m, m.aic\n",
    "            except Exception: pass\n",
    "\n",
    "        # Best ARIMAX by AIC\n",
    "        best_arimax, best_aicx = None, np.inf\n",
    "        if X_tr is not None:\n",
    "            for od in arima_orders:\n",
    "                try:\n",
    "                    mx = fit_sarimax(y_tr, X_tr, od, seasonal_flag)\n",
    "                    if mx.aic < best_aicx: best_arimax, best_aicx = mx, mx.aic\n",
    "                except Exception: pass\n",
    "\n",
    "        # Forecast horizons\n",
    "        for h in horizons:\n",
    "            if t_idx + h >= len(dates): continue\n",
    "            fut_idx = dates[t_idx+1 : t_idx+1+h]\n",
    "            X_fut   = df.loc[fut_idx, EXO] if EXO else None\n",
    "\n",
    "            y_true_last = df.loc[fut_idx[-1], target]\n",
    "            snaive_last = (np.repeat(y_tr.iloc[-12], h)[-1] if len(y_tr)>=12 else y_tr.iloc[-1])\n",
    "\n",
    "            ets_last = np.nan\n",
    "            if ets_fit is not None:\n",
    "                try: ets_last = ets_fit.forecast(h).iloc[-1]\n",
    "                except Exception: pass\n",
    "\n",
    "            arima_last = np.nan\n",
    "            if best_arima is not None:\n",
    "                try: arima_last = best_arima.forecast(h).iloc[-1]\n",
    "                except Exception: pass\n",
    "\n",
    "            arimax_last = np.nan\n",
    "            if best_arimax is not None and X_fut is not None:\n",
    "                try: arimax_last = best_arimax.forecast(h, exog=X_fut).iloc[-1]\n",
    "                except Exception: pass\n",
    "\n",
    "            rows.append({\"t_origin\": origin, \"h\": h, \"y_true\": y_true_last,\n",
    "                         \"snaive\": snaive_last, \"ets\": ets_last,\n",
    "                         \"arima\": arima_last, \"arimax\": arimax_last})\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    metrics_log = metrics_table(results, \"log\")\n",
    "\n",
    "    # DM vs snaive on CV (optional, not saved here to keep files lean)\n",
    "    dm_rows=[]\n",
    "    for h, g in results.groupby(\"h\"):\n",
    "        base_e = g[\"y_true\"] - g[\"snaive\"]\n",
    "        for m in [\"ets\",\"arima\",\"arimax\"]:\n",
    "            if m not in g.columns or g[m].isna().any():\n",
    "                stat, p = np.nan, np.nan\n",
    "            else:\n",
    "                e = g[\"y_true\"] - g[m]\n",
    "                stat, p = dm_test(e.values, base_e.values, h=int(h))\n",
    "            dm_rows.append({\"h\": int(h), \"model\": m, \"DM_stat_vs_snaive\": stat, \"p_value\": p})\n",
    "    dm = pd.DataFrame(dm_rows).sort_values([\"h\",\"model\"])\n",
    "    return results, metrics_log, dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf3fba-8850-40ab-9a41-d01b90ab6c68",
   "metadata": {},
   "source": [
    "### Step 7: Test evaluation (champions only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493b3b2a-731c-42c7-845c-99527ebed277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 7) Test evaluation (champions only) ========================\n",
    "\n",
    "def evaluate_test(df_base, winners: dict, target=TARGET,\n",
    "                  horizons=HORIZONS, arima_orders=ARIMA_ORDERS, min_train=MIN_TRAIN):\n",
    "    df = df_base.copy()\n",
    "    df, EXO = build_exog(df)\n",
    "    df = df.dropna(subset=[target] + EXO)\n",
    "    dates = df.index\n",
    "\n",
    "    rows=[]\n",
    "    for h in horizons:\n",
    "        win = winners.get(h, {\"model\":\"ets\",\"seasonal\":False})\n",
    "        mtype, seas = win[\"model\"], win[\"seasonal\"]\n",
    "\n",
    "        for i in range(len(dates)-h):\n",
    "            origin = dates[i]\n",
    "            target_date = (origin.to_period(\"M\") + h).to_timestamp(\"M\")\n",
    "            if not (TEST_START <= target_date <= TEST_END): continue\n",
    "            if i < min_train: continue\n",
    "\n",
    "            y_tr = df.loc[:origin, target]\n",
    "            X_tr = df.loc[:origin, EXO] if EXO else None\n",
    "            fut_idx = dates[i+1:i+1+h]\n",
    "            X_fut   = df.loc[fut_idx, EXO] if EXO else None\n",
    "\n",
    "            snaive_last = (np.repeat(y_tr.iloc[-12], h)[-1] if len(y_tr)>=12 else y_tr.iloc[-1])\n",
    "            y_true_last = df.loc[fut_idx[-1], target]\n",
    "\n",
    "            ets_last = arima_last = arimax_last = np.nan\n",
    "            if mtype == \"ets\":\n",
    "                try: ets_last = fit_ets(y_tr).forecast(h).iloc[-1]\n",
    "                except Exception: pass\n",
    "            elif mtype == \"arima\":\n",
    "                best, aic = None, np.inf\n",
    "                for od in arima_orders:\n",
    "                    try:\n",
    "                        m = fit_sarimax(y_tr, None, od, seas)\n",
    "                        if m.aic < aic: best, aic = m, m.aic\n",
    "                    except Exception: pass\n",
    "                if best is not None:\n",
    "                    try: arima_last = best.forecast(h).iloc[-1]\n",
    "                    except Exception: pass\n",
    "            elif mtype == \"arimax\":\n",
    "                best, aic = None, np.inf\n",
    "                for od in arima_orders:\n",
    "                    try:\n",
    "                        mx = fit_sarimax(y_tr, X_tr, od, seas)\n",
    "                        if mx.aic < aic: best, aic = mx, mx.aic\n",
    "                    except Exception: pass\n",
    "                if best is not None and X_fut is not None:\n",
    "                    try: arimax_last = best.forecast(h, exog=X_fut).iloc[-1]\n",
    "                    except Exception: pass\n",
    "\n",
    "            rows.append({\"t_origin\": origin, \"h\": h, \"target_date\": target_date,\n",
    "                         \"y_true\": y_true_last, \"snaive\": snaive_last,\n",
    "                         \"ets\": ets_last, \"arima\": arima_last, \"arimax\": arimax_last,\n",
    "                         \"winner_model\": mtype, \"winner_seasonal\": seas})\n",
    "    return pd.DataFrame(rows).sort_values([\"h\",\"target_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ec721-43b6-4dbc-8134-aa5511551ef6",
   "metadata": {},
   "source": [
    "### Step 8: Additional exogenous variables screening (Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "198eff75-d5ac-4102-af1a-8a9dd4345d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 8) Appendix — exogenous screening =======================\n",
    "\n",
    "def appendix_exogenous_quickcheck(df: pd.DataFrame, out_dir: str):\n",
    "    \"\"\"\n",
    "    Produces two Appendix CSVs:\n",
    "      - appendix_leadlag_corr.csv        (lead–lag with Δlog(HPI))\n",
    "      - appendix_oos_singlevar_rmse.csv  (tiny OOS Δlog(HPI) ~ lagged x check)\n",
    "    This does NOT change the main model.\n",
    "    \"\"\"\n",
    "    ser_map = [\n",
    "        (\"OCR\",                  \"ocr_imp\"),\n",
    "        (\"New listings (AKL)\",   \"new_listings_akl_imp\"),\n",
    "        (\"Total stock (AKL)\",    \"total_stock_akl_imp\"),\n",
    "        (\"Sales count (AKL)\",    \"sales_count_akl_imp\"),\n",
    "        (\"Days to sell (AKL)\",   \"days_to_sell_akl_imp\"),\n",
    "        (\"Median price (AKL)\",   \"median_price_akl_imp\"),\n",
    "    ]\n",
    "\n",
    "    # Δlog(HPI)\n",
    "    y = df[\"y_log_imp\"].diff()\n",
    "    leadlag_rows=[]\n",
    "    for label, col in ser_map:\n",
    "        if col not in df.columns: continue\n",
    "        x0 = pd.Series(df[col], index=df.index)\n",
    "        lags = range(0, 7)\n",
    "        corr = {}\n",
    "        for L in lags:\n",
    "            xx = x0.shift(L).reindex(y.index)\n",
    "            c  = np.corrcoef(y.dropna(), xx.loc[y.dropna().index].dropna())[0,1] if xx.notna().sum()>24 else np.nan\n",
    "            corr[f\"lag{L}\"] = c\n",
    "        # pick best absolute\n",
    "        best_L = int(max(lags, key=lambda L: abs(corr.get(f\"lag{L}\", np.nan)) if pd.notna(corr.get(f\"lag{L}\", np.nan)) else -1))\n",
    "        leadlag_rows.append({\n",
    "            \"series\": label, \"col\": col, **corr,\n",
    "            \"best_lag\": best_L,\n",
    "            \"best_corr_signed\": corr.get(f\"lag{best_L}\", np.nan),\n",
    "            \"best_abs_corr\": abs(corr.get(f\"lag{best_L}\", np.nan)) if pd.notna(corr.get(f\"lag{best_L}\", np.nan)) else np.nan\n",
    "        })\n",
    "    pd.DataFrame(leadlag_rows).to_csv(os.path.join(out_dir, \"appendix_leadlag_corr.csv\"), index=False)\n",
    "\n",
    "    # Tiny OOS check on Δlog(HPI) ~ lagged x  (pseudo-regression via one-step naive vs x-lag)\n",
    "    oos_rows=[]\n",
    "    for label, col in ser_map:\n",
    "        if col not in df.columns: continue\n",
    "        best_lag = int(pd.read_csv(os.path.join(out_dir, \"appendix_leadlag_corr.csv\"))\n",
    "                       .query(\"col == @col\")[\"best_lag\"].iloc[0])\n",
    "        y2 = y.copy()\n",
    "        xL = df[col].shift(best_lag)\n",
    "        # align\n",
    "        z = pd.concat([y2, xL], axis=1, keys=[\"dy\", \"x\"]).dropna()\n",
    "        if len(z) < 36:\n",
    "            oos_rows.append({\"series\": label, \"col\": col, \"chosen_causal_lag\": best_lag,\n",
    "                             \"RMSE_model\": np.nan, \"RMSE_naive0\": np.nan,\n",
    "                             \"%_improvement_vs_naive0\": np.nan, \"n_test_obs\": len(z)})\n",
    "            continue\n",
    "        # split 70/30\n",
    "        cut = int(len(z)*0.7)\n",
    "        tr, te = z.iloc[:cut], z.iloc[cut:]\n",
    "        # simple linear fit dy ~ x on train\n",
    "        xtr = tr[\"x\"].values; ytr = tr[\"dy\"].values\n",
    "        beta = np.dot(xtr, ytr) / np.dot(xtr, xtr) if np.dot(xtr, xtr) != 0 else 0.0\n",
    "        yhat = te[\"x\"].values * beta\n",
    "        rmse_model = float(np.sqrt(np.mean((te[\"dy\"].values - yhat)**2)))\n",
    "        rmse_naive = float(np.sqrt(np.mean((te[\"dy\"].values - 0.0)**2)))  # zero-change baseline on dy\n",
    "        gain = 100.0 * (rmse_naive - rmse_model) / rmse_naive if rmse_naive>0 else np.nan\n",
    "\n",
    "        oos_rows.append({\"series\": label, \"col\": col, \"chosen_causal_lag\": best_lag,\n",
    "                         \"RMSE_model\": rmse_model, \"RMSE_naive0\": rmse_naive,\n",
    "                         \"%_improvement_vs_naive0\": gain, \"n_test_obs\": len(te)})\n",
    "    pd.DataFrame(oos_rows).to_csv(os.path.join(out_dir, \"appendix_oos_singlevar_rmse.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb30ddbf-ec36-4830-a12c-20ac2dc5f86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\appendix_A1_leadlag_corr_matrix.csv\n",
      "Saved figure: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\appendix_figs\\Fig_A1_leadlag_corr_heatmap.png\n",
      "Saved figure: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\appendix_figs\\Fig_A1b_leadlag_corr_heatmap_annotated.png\n"
     ]
    }
   ],
   "source": [
    "# === Appendix A1: lead–lag correlation matrix + heatmap ===\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT_DIR = r\"C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\"\n",
    "src = os.path.join(OUT_DIR, \"appendix_leadlag_corr.csv\")\n",
    "fig_dir = os.path.join(OUT_DIR, \"appendix_figs\"); os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# 1) Load and pivot to matrix (rows=series, cols=lag0..lag6)\n",
    "df = pd.read_csv(src)\n",
    "# Use the human-readable 'series' as row labels, fall back to 'col' if needed\n",
    "row_label = \"series\" if \"series\" in df.columns else \"col\"\n",
    "lag_cols = [c for c in df.columns if c.startswith(\"lag\")]\n",
    "mat = (df[[row_label] + lag_cols]\n",
    "       .set_index(row_label)\n",
    "       .sort_index())\n",
    "\n",
    "# Optional: round for a clean table in the appendix\n",
    "mat_rounded = mat.round(3)\n",
    "mat_path = os.path.join(OUT_DIR, \"appendix_A1_leadlag_corr_matrix.csv\")\n",
    "mat_rounded.to_csv(mat_path, index=True)\n",
    "print(\"Saved table:\", mat_path)\n",
    "\n",
    "# 2) Heatmap (matplotlib only)\n",
    "plt.figure(figsize=(10, max(3, 0.5*len(mat))))\n",
    "im = plt.imshow(mat.values, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label=\"Correlation with Δlog(HPI)\")\n",
    "plt.xticks(ticks=np.arange(len(lag_cols)), labels=lag_cols, rotation=0)\n",
    "plt.yticks(ticks=np.arange(len(mat.index)), labels=mat.index)\n",
    "plt.title(\"Lead–lag correlations with Δlog(HPI) (positive = co-move)\")\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(fig_dir, \"Fig_A1_leadlag_corr_heatmap.png\")\n",
    "plt.savefig(fig_path, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved figure:\", fig_path)\n",
    "\n",
    "# 3) (Optional) annotate a version with numbers for review (not for print if busy)\n",
    "plt.figure(figsize=(10, max(3, 0.5*len(mat))))\n",
    "im = plt.imshow(mat.values, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label=\"Correlation\")\n",
    "plt.xticks(ticks=np.arange(len(lag_cols)), labels=lag_cols, rotation=0)\n",
    "plt.yticks(ticks=np.arange(len(mat.index)), labels=mat.index)\n",
    "# add text annotations\n",
    "vals = mat.round(2).values\n",
    "for i in range(vals.shape[0]):\n",
    "    for j in range(vals.shape[1]):\n",
    "        plt.text(j, i, f\"{vals[i,j]:.2f}\",\n",
    "                 ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.title(\"Lead–lag correlations (annotated)\")\n",
    "plt.tight_layout()\n",
    "fig_path2 = os.path.join(fig_dir, \"Fig_A1b_leadlag_corr_heatmap_annotated.png\")\n",
    "plt.savefig(fig_path2, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved figure:\", fig_path2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c27801-2009-4354-a716-3487f02936e9",
   "metadata": {},
   "source": [
    "### Step 9: Main Analysis Parts & Printing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe72e04-82dd-4c18-a41f-4b36750f7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ 9) MAIN ======================================\n",
    "\n",
    "def main():\n",
    "    # --- Load main assembled panel ---\n",
    "    if not os.path.exists(PANEL_PATH):\n",
    "        raise FileNotFoundError(f\"monthly_panel.csv not found at: {PANEL_PATH}\")\n",
    "    raw = (pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
    "             .set_index(\"date\")\n",
    "             .asfreq(\"M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876fb18-3b8d-4c4f-ad4a-38c02edb98dd",
   "metadata": {},
   "source": [
    "#### Step 9.1: Printing causal imputation (in-memory) + save the exact panel used (audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89071cc3-a809-43eb-bcce-79480d50975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\monthly_panel_imputed_causal.csv\n",
      "Saved: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\imputation_report_causal.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== load panel + causal imputation + save audit files (standalone cell) =====\n",
    "\n",
    "# Load main assembled panel\n",
    "if not os.path.exists(PANEL_PATH):\n",
    "    raise FileNotFoundError(f\"monthly_panel.csv not found at: {PANEL_PATH}\")\n",
    "\n",
    "raw = (pd.read_csv(PANEL_PATH, parse_dates=[\"date\"])\n",
    "         .set_index(\"date\")\n",
    "         .asfreq(\"M\"))\n",
    "\n",
    "# Causal imputation (in-memory) + save the exact panel used\n",
    "data = build_imputed_panel(raw)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "data.to_csv(os.path.join(OUT_DIR, \"monthly_panel_imputed_causal.csv\"),\n",
    "            index=True, index_label=\"date\")\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"monthly_panel_imputed_causal.csv\"))\n",
    "\n",
    "# Quick imputation report\n",
    "rep = []\n",
    "for base in [\"hpi_index\",\"mort_rate_1y\",\"mort_rate_float\",\"ocr\",\n",
    "             \"dwellings_consent_count\",\"new_listings_akl\",\"total_stock_akl\",\n",
    "             \"sales_count_akl\",\"days_to_sell_akl\",\"filled_jobs_nz\",\"net_migration_nz\"]:\n",
    "    miss_col, imp_col = f\"{base}_miss\", f\"{base}_imp\"\n",
    "    if (miss_col in data.columns) or (imp_col in data.columns):\n",
    "        rep.append({\n",
    "            \"series\": base,\n",
    "            \"n_rows\": len(data),\n",
    "            \"n_missing_flag\": int(data[miss_col].sum()) if miss_col in data.columns else None,\n",
    "            \"has_imp_col\": imp_col in data.columns\n",
    "        })\n",
    "\n",
    "pd.DataFrame(rep).to_csv(os.path.join(OUT_DIR, \"imputation_report_causal.csv\"), index=False)\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"imputation_report_causal.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a43b71-9b7f-49cd-bcf2-75fefc271ea0",
   "metadata": {},
   "source": [
    "#### Step 9.2: Cross-validation (non-seasonal & seasonal flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e08894e-e729-4248-9d0f-eb886e2ef328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV Champions (2018-01 → 2024-08) ===\n",
      " h winner_model  winner_seasonal  winner_RMSE_log\n",
      " 1        arima            False         0.015591\n",
      " 3        arima            False         0.035771\n",
      " 6        arima            False         0.064802\n",
      "12       arimax            False         0.097382\n",
      "\n",
      "Saved: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\cv_allmodels_logrmse.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Cross-validation (non-seasonal & seasonal flags) ---\n",
    "cv_non_res, cv_non_met, _ = evaluate_cv(data, seasonal_flag=False, target=TARGET)\n",
    "cv_sea_res, cv_sea_met, _  = evaluate_cv(data, seasonal_flag=True,  target=TARGET)\n",
    "\n",
    "cv_non_met.to_csv(os.path.join(OUT_DIR, \"cv_metrics_log_nonseasonal.csv\"), index=False)\n",
    "cv_sea_met.to_csv(os.path.join(OUT_DIR, \"cv_metrics_log_seasonal.csv\"), index=False)\n",
    "\n",
    "# Merge to compare seasonal vs non-seasonal\n",
    "keep = [\"h\",\"snaive_RMSE\",\"ets_RMSE\",\"arima_RMSE\",\"arimax_RMSE\"]\n",
    "A = cv_non_met[keep].rename(columns=lambda c: c if c==\"h\" else f\"non_{c}\")\n",
    "B = cv_sea_met[keep].rename(columns=lambda c: c if c==\"h\" else f\"seas_{c}\")\n",
    "M = A.merge(B, on=\"h\", how=\"inner\")\n",
    "\n",
    "# (NEW) Long table with ALL models per horizon\n",
    "all_rows = []\n",
    "winners, winner_rows = {}, []\n",
    "for _, r in M.iterrows():\n",
    "    h = int(r[\"h\"])\n",
    "    candidates = {\n",
    "        (\"snaive\", False): r[\"non_snaive_RMSE\"],\n",
    "        (\"ets\",    False): r[\"non_ets_RMSE\"],\n",
    "        (\"arima\",  False): r[\"non_arima_RMSE\"],\n",
    "        (\"arimax\", False): r[\"non_arimax_RMSE\"],\n",
    "        (\"arima\",  True ): r[\"seas_arima_RMSE\"],\n",
    "        (\"arimax\", True ): r[\"seas_arimax_RMSE\"],\n",
    "    }\n",
    "    # Write all candidates\n",
    "    for (m, seas), rmse in candidates.items():\n",
    "        all_rows.append({\n",
    "            \"h\": h, \"model\": m, \"seasonal\": bool(seas), \"RMSE_log\": float(rmse)\n",
    "        })\n",
    "    # Winner\n",
    "    best_key = min(candidates, key=lambda k: candidates[k])\n",
    "    winners[h] = {\"model\": best_key[0], \"seasonal\": best_key[1],\n",
    "                  \"cv_rmse_log\": float(candidates[best_key])}\n",
    "    winner_rows.append({\"h\": h, \"winner_model\": best_key[0],\n",
    "                        \"winner_seasonal\": best_key[1],\n",
    "                        \"winner_RMSE_log\": float(candidates[best_key])})\n",
    "\n",
    "cv_all = pd.DataFrame(all_rows).sort_values([\"h\",\"model\",\"seasonal\"])\n",
    "cv_all.to_csv(os.path.join(OUT_DIR, \"cv_allmodels_logrmse.csv\"), index=False)\n",
    "\n",
    "champ_cv = pd.DataFrame(winner_rows).sort_values(\"h\")\n",
    "champ_cv.to_csv(os.path.join(OUT_DIR, \"cv_champions_by_horizon.csv\"), index=False)\n",
    "\n",
    "print(\"\\n=== CV Champions (2018-01 → 2024-08) ===\")\n",
    "print(champ_cv.to_string(index=False))\n",
    "print(\"\\nSaved:\", os.path.join(OUT_DIR, \"cv_allmodels_logrmse.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f91df-31e2-4eda-b402-5e3784423958",
   "metadata": {},
   "source": [
    "#### Step 9.3: Test evaluation (target months 2024-09 → 2025-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a272111-ea0a-46e6-b950-9634f6572296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST Champions (target 2024-09 → 2025-08) ===\n",
      " h winner_test  MAE_log  RMSE_log  MAPE_log  snaive_RMSE_log  ets_RMSE_log  arima_RMSE_log  arimax_RMSE_log\n",
      " 1       arima 0.009719  0.010778  0.119761         0.017668           NaN        0.010778              NaN\n",
      " 3       arima 0.016250  0.019891  0.200257         0.023272           NaN        0.019891              NaN\n",
      " 6       arima 0.020351  0.025501  0.250913         0.032773           NaN        0.025501              NaN\n",
      "12      snaive 0.021214  0.027841  0.261549         0.027841           NaN             NaN         0.074024\n",
      "Saved: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\test_metrics_log_allmodels.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Test evaluation (target months 2024-09 → 2025-08) ---\n",
    "test = evaluate_test(data, winners, target=TARGET)\n",
    "test = test[(test[\"target_date\"] >= TEST_START) & (test[\"target_date\"] <= TEST_END)]\n",
    "test.to_csv(os.path.join(OUT_DIR, \"test_predictions_laststep.csv\"), index=False)\n",
    "\n",
    "def metr(g, col):\n",
    "    y = g[\"y_true\"].to_numpy(); yhat = g[col].to_numpy()\n",
    "    e = y - yhat\n",
    "    return dict(MAE_log=float(np.mean(np.abs(e))),\n",
    "                RMSE_log=float(np.sqrt(np.mean(e**2))),\n",
    "                MAPE_log=float(np.mean(np.abs(e/np.where(np.abs(y)<1e-12, np.nan, y)))*100))\n",
    "\n",
    "# (NEW) all models on TEST — log metrics\n",
    "log_rows_all, rows_winner = [], []\n",
    "for h, g in test.groupby(\"h\"):\n",
    "    models = [m for m in [\"snaive\",\"ets\",\"arima\",\"arimax\"]\n",
    "              if m in g.columns and g[m].notna().any()]\n",
    "    stats = {m: metr(g, m) for m in models}\n",
    "    # write all\n",
    "    for m in models:\n",
    "        log_rows_all.append({\"h\": int(h), \"model\": m, **stats[m]})\n",
    "    # pick winner\n",
    "    winner = min(stats, key=lambda m: stats[m][\"RMSE_log\"])\n",
    "    rows_winner.append({\"h\": int(h), \"winner_test\": winner, **stats[winner],\n",
    "                        \"snaive_RMSE_log\": stats.get(\"snaive\",{}).get(\"RMSE_log\", np.nan),\n",
    "                        \"ets_RMSE_log\":    stats.get(\"ets\",{}).get(\"RMSE_log\", np.nan),\n",
    "                        \"arima_RMSE_log\":  stats.get(\"arima\",{}).get(\"RMSE_log\", np.nan),\n",
    "                        \"arimax_RMSE_log\": stats.get(\"arimax\",{}).get(\"RMSE_log\", np.nan)})\n",
    "\n",
    "test_log_all = pd.DataFrame(log_rows_all).sort_values([\"h\",\"model\"])\n",
    "test_log_all.to_csv(os.path.join(OUT_DIR, \"test_metrics_log_allmodels.csv\"), index=False)\n",
    "\n",
    "champ_test = pd.DataFrame(rows_winner).sort_values(\"h\")\n",
    "champ_test.to_csv(os.path.join(OUT_DIR, \"final_test_champions_by_horizon.csv\"), index=False)\n",
    "\n",
    "print(\"\\n=== TEST Champions (target 2024-09 → 2025-08) ===\")\n",
    "print(champ_test.to_string(index=False))\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"test_metrics_log_allmodels.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553bf69-80eb-4a12-bd46-a4c85574f246",
   "metadata": {},
   "source": [
    "#### Step 9.4: DM test (winner vs seasonal-naive) on TEST (log scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991210a0-2119-4bd4-9db5-2b2504bbba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DM (winner vs seasonal-naïve, log) on TEST ===\n",
      " h winner_model  DM_stat_winner_vs_snaive  p_value\n",
      " 1        arima                 -1.675568 0.093823\n",
      " 3        arima                 -0.538923 0.589940\n",
      " 6        arima                 -1.046331 0.295408\n",
      "12       snaive                  0.000000 1.000000\n"
     ]
    }
   ],
   "source": [
    "    # --- DM test (winner vs seasonal-naive) on TEST (log scale) ---\n",
    "    dm_rows=[]\n",
    "    for h, g in test.groupby(\"h\"):\n",
    "        y = g[\"y_true\"].to_numpy()\n",
    "        s = g[\"snaive\"].to_numpy()\n",
    "        win_name = champ_test.loc[champ_test[\"h\"]==h, \"winner_test\"].values[0]\n",
    "        w = g[win_name].to_numpy()\n",
    "        if np.allclose(w, s, equal_nan=False):\n",
    "            stat, p = 0.0, 1.0\n",
    "        else:\n",
    "            stat, p = dm_test(y - w, y - s, h=int(h))\n",
    "        dm_rows.append({\"h\": int(h), \"winner_model\": win_name,\n",
    "                        \"DM_stat_winner_vs_snaive\": stat, \"p_value\": p})\n",
    "    dm_test_win = pd.DataFrame(dm_rows).sort_values(\"h\")\n",
    "    dm_test_win.to_csv(os.path.join(OUT_DIR, \"test_dm_winner_vs_snaive.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n=== DM (winner vs seasonal-naïve, log) on TEST ===\")\n",
    "    print(dm_test_win.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29414286-8052-409f-a4ce-9f4016d99192",
   "metadata": {},
   "source": [
    "#### Step 9.5: Level metrics for winners (intuitive HPI units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad0103f-db64-494c-81aa-3c854ddd7527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\test_metrics_level_allmodels.csv\n",
      "\n",
      "Level metrics (RMSE_level in HPI units):\n",
      " h  model  MAE_level  RMSE_level  MAPE_level\n",
      " 1  arima  32.558034   36.131299    0.973030\n",
      " 1 snaive  49.416667   60.334484    1.468780\n",
      " 3  arima  54.247804   66.253432    1.622499\n",
      " 3 snaive  65.333333   79.015821    1.958306\n",
      " 6  arima  67.958940   85.069473    2.040475\n",
      " 6 snaive  93.916667  110.556547    2.825975\n",
      "12 arimax 248.729413  259.377615    7.420794\n",
      "12 snaive  71.583333   94.289890    2.149013\n"
     ]
    }
   ],
   "source": [
    "# --- Level metrics for ALL models (HPI units) ---\n",
    "level_rows_all = []\n",
    "for h, g in test.groupby(\"h\"):\n",
    "    y_lvl = np.exp(g[\"y_true\"].to_numpy())\n",
    "    for m in [c for c in [\"snaive\",\"ets\",\"arima\",\"arimax\"] if c in g.columns and g[c].notna().any()]:\n",
    "        w_lvl = np.exp(g[m].to_numpy())\n",
    "        e = y_lvl - w_lvl\n",
    "        level_rows_all.append({\n",
    "            \"h\": int(h), \"model\": m,\n",
    "            \"MAE_level\": float(np.mean(np.abs(e))),\n",
    "            \"RMSE_level\": float(np.sqrt(np.mean(e**2))),\n",
    "            \"MAPE_level\": float(np.mean(np.abs(e/np.where(y_lvl==0,np.nan,y_lvl)))*100)\n",
    "        })\n",
    "\n",
    "test_level_all = pd.DataFrame(level_rows_all).sort_values([\"h\",\"model\"])\n",
    "test_level_all.to_csv(os.path.join(OUT_DIR, \"test_metrics_level_allmodels.csv\"), index=False)\n",
    "\n",
    "print(\"\\nSaved:\", os.path.join(OUT_DIR, \"test_metrics_level_allmodels.csv\"))\n",
    "print(\"\\nLevel metrics (RMSE_level in HPI units):\")\n",
    "print(test_level_all.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380aa3c4-4b31-4c1b-9f92-ee5f63763eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level metrics (RMSE_level in HPI units):\n",
      " h  MAE_level  RMSE_level  MAPE_level\n",
      " 1  32.558034   36.131299    0.973030\n",
      " 3  54.247804   66.253432    1.622499\n",
      " 6  67.958940   85.069473    2.040475\n",
      "12  71.583333   94.289890    2.149013\n"
     ]
    }
   ],
   "source": [
    "    # --- Level metrics for winners (intuitive HPI units) ---\n",
    "    lvl_rows=[]\n",
    "    for h, g in test.groupby(\"h\"):\n",
    "        win_name = champ_test.loc[champ_test[\"h\"]==h, \"winner_test\"].values[0]\n",
    "        y_lvl = np.exp(g[\"y_true\"].to_numpy())\n",
    "        w_lvl = np.exp(g[win_name].to_numpy())\n",
    "        e = y_lvl - w_lvl\n",
    "        lvl_rows.append({\"h\": int(h),\n",
    "                         \"MAE_level\": float(np.mean(np.abs(e))),\n",
    "                         \"RMSE_level\": float(np.sqrt(np.mean(e**2))),\n",
    "                         \"MAPE_level\": float(np.mean(np.abs(e/np.where(y_lvl==0,np.nan,y_lvl)))*100)})\n",
    "    test_metrics_level = pd.DataFrame(lvl_rows).sort_values(\"h\")\n",
    "    test_metrics_level.to_csv(os.path.join(OUT_DIR, \"test_metrics_winners_level.csv\"), index=False)\n",
    "\n",
    "    print(\"\\nLevel metrics (RMSE_level in HPI units):\")\n",
    "    print(test_metrics_level.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4013757-3c42-4e2b-bd27-6659eb3f7ee7",
   "metadata": {},
   "source": [
    "#### Step 9.6: Plots: Actual vs Winner (level scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3a0e4fe-8516-49ec-bfc7-204e957eb553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendix_exogenous_quickcheck(df, out_dir):\n",
    "    \"\"\"\n",
    "    Save two appendix tables:\n",
    "      1) Lead-lag correlations of Δlog(HPI) with candidate drivers (lags 0..6)\n",
    "      2) Tiny OOS check: RMSE of one-step Δlog(HPI) using a single lagged driver vs naive(0)\n",
    "    \"\"\"\n",
    "    y = df[\"y_log_imp\"].diff().rename(\"dlog_hpi\")  # Δlog(HPI)\n",
    "    candidates = [\n",
    "        (\"OCR\",                    \"ocr_imp\"),\n",
    "        (\"New listings (AKL)\",     \"new_listings_akl_imp\"),\n",
    "        (\"Total stock (AKL)\",      \"total_stock_akl_imp\"),\n",
    "        (\"Sales count (AKL)\",      \"sales_count_akl_imp\"),\n",
    "        (\"Days to sell (AKL)\",     \"days_to_sell_akl_imp\"),\n",
    "        (\"Median price (AKL)\",     \"median_price_akl_imp\"),\n",
    "    ]\n",
    "    lags = [0,1,2,3,4,5,6]\n",
    "\n",
    "    # ---------- A1) Lead–lag correlations (aligned inner join) ----------\n",
    "    rows = []\n",
    "    for label, col in candidates:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        x0 = df[col]\n",
    "        corr = {}\n",
    "        for L in lags:\n",
    "            xx = x0.shift(L)\n",
    "            pair = pd.concat([y, xx], axis=1).dropna()   # inner align, drop any NaNs\n",
    "            if len(pair) >= 24 and pair.iloc[:,1].std() > 0 and pair.iloc[:,0].std() > 0:\n",
    "                c = pair.iloc[:,0].corr(pair.iloc[:,1])\n",
    "            else:\n",
    "                c = np.nan\n",
    "            corr[f\"lag{L}\"] = c\n",
    "        # pick best |corr|\n",
    "        best_L, best_c = max(\n",
    "            ((L, abs(corr[f\"lag{L}\"])) for L in lags if np.isfinite(corr[f\"lag{L}\"])),\n",
    "            key=lambda t: t[1],\n",
    "            default=(np.nan, np.nan)\n",
    "        )\n",
    "        best_signed = np.sign(corr.get(f\"lag{best_L}\", np.nan)) * best_c if np.isfinite(best_L) else np.nan\n",
    "        rows.append({\n",
    "            \"series\": label, \"col\": col, **corr,\n",
    "            \"best_lag\": best_L,\n",
    "            \"best_corr_signed\": best_signed,\n",
    "            \"best_abs_corr\": best_c\n",
    "        })\n",
    "\n",
    "    a1 = pd.DataFrame(rows)\n",
    "    a1.to_csv(os.path.join(out_dir, \"appendix_leadlag_corr.csv\"), index=False)\n",
    "\n",
    "    # ---------- A2) Tiny OOS single-variable check ----------\n",
    "    # Model: dlog_hpi_t = α + β * x_{t-L} + ε, rolling one-step, compare RMSE to naive0\n",
    "    # We'll use the *causal* lag that had the best absolute corr but force L>=1\n",
    "    rows = []\n",
    "    for label, col in candidates:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        # choose best causal lag (>=1); fallback to 1 if none\n",
    "        sub = a1.loc[a1[\"col\"] == col]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        cand = [(int(L), abs(sub.iloc[0][f\"lag{L}\"])) for L in lags if L >= 1 and np.isfinite(sub.iloc[0][f\"lag{L}\"])]\n",
    "        chosen_L = max(cand, key=lambda t: t[1])[0] if cand else 1\n",
    "\n",
    "        # Build aligned frame for OOS\n",
    "        xx = df[col].shift(chosen_L)\n",
    "        frame = pd.concat([y, xx], axis=1).dropna()\n",
    "        frame.columns = [\"dlog_hpi\", \"xlag\"]\n",
    "        # Split train/test roughly at 2024-08 end (consistent with main analysis)\n",
    "        split_date = pd.Timestamp(\"2024-08-31\")\n",
    "        tr = frame.loc[:split_date]\n",
    "        te = frame.loc[split_date + pd.offsets.MonthEnd(1):]\n",
    "\n",
    "        if len(tr) >= 24 and len(te) >= 6:\n",
    "            # OLS on train\n",
    "            Xtr = np.c_[np.ones(len(tr)), tr[\"xlag\"].values]\n",
    "            ytr = tr[\"dlog_hpi\"].values\n",
    "            try:\n",
    "                beta = np.linalg.lstsq(Xtr, ytr, rcond=None)[0]\n",
    "                # one-step predictions on test (static regression)\n",
    "                Xte = np.c_[np.ones(len(te)), te[\"xlag\"].values]\n",
    "                yhat = Xte @ beta\n",
    "                ytrue = te[\"dlog_hpi\"].values\n",
    "                rmse_model = float(np.sqrt(np.mean((ytrue - yhat)**2)))\n",
    "                # Naive(0): predict zero change\n",
    "                rmse_naive0 = float(np.sqrt(np.mean((ytrue - 0.0)**2)))\n",
    "                rows.append({\n",
    "                    \"series\": label,\n",
    "                    \"col\": col,\n",
    "                    \"chosen_causal_lag\": chosen_L,\n",
    "                    \"RMSE_model\": rmse_model,\n",
    "                    \"RMSE_naive0\": rmse_naive0,\n",
    "                    \"%_improvement_vs_naive0\": 100.0*(rmse_naive0 - rmse_model)/rmse_naive0 if rmse_naive0>0 else np.nan,\n",
    "                    \"n_test_obs\": int(len(te))\n",
    "                })\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    a2 = pd.DataFrame(rows)\n",
    "    a2.to_csv(os.path.join(out_dir, \"appendix_oos_singlevar_rmse.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a883fb5-3081-4708-8ff5-e5096e80e0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved plots to: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\plots_test\n",
      "Saved Appendix tables: C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\appendix_leadlag_corr.csv and C:\\AUT_Lecture\\Semester-2\\ENGE817_STEM_Research_Method\\Data_Collection\\output\\appendix_oos_singlevar_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # ... my existing steps that produce `test`, `champ_test`, and `data` ...\n",
    "\n",
    "    # --- Plots: Actual vs Winner (level scale) ---\n",
    "    plot_dir = os.path.join(OUT_DIR, \"plots_test\")\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    for h, g in test.groupby(\"h\"):\n",
    "        win_name = champ_test.loc[champ_test[\"h\"] == h, \"winner_test\"].values[0]\n",
    "        gg = g.sort_values(\"target_date\")\n",
    "        y_lvl, w_lvl = np.exp(gg[\"y_true\"]), np.exp(gg[win_name])\n",
    "\n",
    "        plt.figure(figsize=(8, 4.5))\n",
    "        plt.plot(gg[\"target_date\"], y_lvl, label=\"Actual\")\n",
    "        plt.plot(gg[\"target_date\"], w_lvl, label=f\"Winner (h={int(h)}: {win_name})\")\n",
    "        plt.title(f\"Auckland HPI — Test window (h={int(h)})\")\n",
    "        plt.xlabel(\"Target month\")\n",
    "        plt.ylabel(\"HPI level\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, f\"test_actual_vs_winner_h{int(h)}.png\"), dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"\\nSaved plots to: {plot_dir}\")\n",
    "\n",
    "    # --- Appendix screening (does not alter main model) ---\n",
    "    appendix_exogenous_quickcheck(data, OUT_DIR)\n",
    "    print(\n",
    "        \"Saved Appendix tables:\",\n",
    "        os.path.join(OUT_DIR, \"appendix_leadlag_corr.csv\"),\n",
    "        \"and\",\n",
    "        os.path.join(OUT_DIR, \"appendix_oos_singlevar_rmse.csv\"),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
